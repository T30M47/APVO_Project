docker exec spark spark-submit --master local[*] --driver-class-path /app/postgresql-42.7.1.jar /app/warehouse.py
 docker exec -it postgres_warehouse psql -U postgres -d warehouse
  docker exec -it postgres_transactions psql -U postgres -d transactions
  docker system prune -a
   docker-compose up --build
    docker-compose down

    REDOSLIJED NAKON PODIZANJA SVIH KONTEJNERA:
    docker exec spark spark-submit --master local[*] --driver-class-path /app/postgresql-42.7.1.jar /app/skladiste//warehouse.py
    docker exec dash_web_app python Dash/app.py
   
    ZA NAPRAVIT PREDIKCIJE:
    docker exec dash_web_app python Dash/forecast.py
    i onda kopiraj iz kontejnera lokalno i stavi u Dash mapu i onda u app.py citaj iz tog csva
    docker cp dash_web_app:/app/forecast_transactions_30_days.csv D://

da se ne mora sve ponovno pokretat:
docker-compose stop dash_web_app
docker-compose rm -f dash_web_app
docker-compose up -d --build dash_web_app
docker exec dash_web_app python Dash/app.py